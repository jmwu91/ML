{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import those package we need \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "from tqdm import tqdm  # 引入 tqdm\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import precision_score, recall_score, roc_curve, auc, f1_score, accuracy_score, classification_report, confusion_matrix, roc_auc_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"/home/jmwu/桌面/ML/HW/mid/X_test_clean.csv\")\n",
    "y_test = pd.read_csv(\"/home/jmwu/桌面/ML/HW/mid/y_test_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.3.0 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.3.0 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 載入 LightGBM 模型\n",
    "bst = lgb.Booster(model_file = \"/home/jmwu/桌面/ML/HW/mid/model_results/lightgbm_model.txt\")\n",
    "\n",
    "# 載入 Random Forest 模型\n",
    "rf_classifier = joblib.load(\"/home/jmwu/桌面/ML/HW/mid/model_results/random_forest_model.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeClassifier' object has no attribute 'monotonic_cst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m y_probabilities_lgbm \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mpredict(X_test, num_iteration \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mbest_iteration)\n\u001b[0;32m----> 2\u001b[0m y_probabilities_rf \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m rf_classifier\u001b[38;5;241m.\u001b[39mestimators_], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# y_probabilities_xgb = best_xgb_model_in_grid.predict_proba(X_test)[:, 1]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/tree/_classes.py:1042\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.predict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict class probabilities of the input samples X.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \n\u001b[1;32m   1020\u001b[0m \u001b[38;5;124;03mThe predicted class probability is the fraction of samples of the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;124;03m    classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1042\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/tree/_classes.py:485\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[0;32m--> 485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_support_missing_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    486\u001b[0m         force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/tree/_classes.py:188\u001b[0m, in \u001b[0;36mBaseDecisionTree._support_missing_values\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_support_missing_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m issparse(X)\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_nan\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 188\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonotonic_cst\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'monotonic_cst'"
     ]
    }
   ],
   "source": [
    "y_probabilities_lgbm = bst.predict(X_test, num_iteration = bst.best_iteration)\n",
    "y_probabilities_rf = np.mean([estimator.predict_proba(X_test)[:, 1] for estimator in rf_classifier.estimators_], axis=0)\n",
    "# y_probabilities_xgb = best_xgb_model_in_grid.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 3 model (lgbm + rf + xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_best_threshold(y_true, y_prob, thresholds):\n",
    "#     best_f1 = 0\n",
    "#     best_threshold = 0\n",
    "#     for threshold in thresholds:\n",
    "#         y_pred = (y_prob >= threshold).astype(int)\n",
    "#         f1 = f1_score(y_true, y_pred)\n",
    "#         if f1 > best_f1:\n",
    "#             best_f1 = f1\n",
    "#             best_threshold = threshold\n",
    "#     return best_threshold, best_f1\n",
    "\n",
    "# # 使用更精細的閾值範圍\n",
    "# thresholds = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "# # 找到每個模型的最佳閾值\n",
    "# best_threshold_lgbm, best_f1_lgbm = find_best_threshold(y_test.label, y_probabilities_lgbm, thresholds)\n",
    "# best_threshold_xgb, best_f1_xgb = find_best_threshold(y_test.label, y_probabilities_xgb, thresholds)\n",
    "# best_threshold_rf, best_f1_rf = find_best_threshold(y_test.label, y_probabilities_rf, thresholds)\n",
    "\n",
    "# print(f\"LightGBM - Best Threshold: {best_threshold_lgbm:.2f}, Best F1: {best_f1_lgbm:.4f}\")\n",
    "# print(f\"XGBoost - Best Threshold: {best_threshold_xgb:.2f}, Best F1: {best_f1_xgb:.4f}\")\n",
    "# print(f\"Random Forest - Best Threshold: {best_threshold_rf:.2f}, Best F1: {best_f1_rf:.4f}\")\n",
    "\n",
    "# # 計算並繪製各個閾值下的F1分數\n",
    "# f1_scores_lgbm = [f1_score(y_test.label, (y_probabilities_lgbm >= t).astype(int)) for t in thresholds]\n",
    "# f1_scores_xgb = [f1_score(y_test.label, (y_probabilities_xgb >= t).astype(int)) for t in thresholds]\n",
    "# f1_scores_rf = [f1_score(y_test.label, (y_probabilities_rf >= t).astype(int)) for t in thresholds]\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(thresholds, f1_scores_lgbm, label='LightGBM')\n",
    "# plt.plot(thresholds, f1_scores_xgb, label='XGBoost')\n",
    "# plt.plot(thresholds, f1_scores_rf, label='Random Forest')\n",
    "# plt.axvline(x=best_threshold_lgbm, color='blue', linestyle='--', label='LightGBM Best')\n",
    "# plt.axvline(x=best_threshold_xgb, color='orange', linestyle='--', label='XGBoost Best')\n",
    "# plt.axvline(x=best_threshold_rf, color='green', linestyle='--', label='Random Forest Best')\n",
    "# plt.title('F1 Score vs Threshold')\n",
    "# plt.xlabel('Threshold')\n",
    "# plt.ylabel('F1 Score')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # 計算並打印最佳閾值下的精確率和召回率\n",
    "# precision_lgbm = precision_score(y_test.label, (y_probabilities_lgbm >= best_threshold_lgbm).astype(int))\n",
    "# recall_lgbm = recall_score(y_test.label, (y_probabilities_lgbm >= best_threshold_lgbm).astype(int))\n",
    "\n",
    "# precision_xgb = precision_score(y_test.label, (y_probabilities_xgb >= best_threshold_xgb).astype(int))\n",
    "# recall_xgb = recall_score(y_test.label, (y_probabilities_xgb >= best_threshold_xgb).astype(int))\n",
    "\n",
    "# precision_rf = precision_score(y_test.label, (y_probabilities_rf >= best_threshold_rf).astype(int))\n",
    "# recall_rf = recall_score(y_test.label, (y_probabilities_rf >= best_threshold_rf).astype(int))\n",
    "\n",
    "# print(f\"LightGBM - Precision: {precision_lgbm:.4f}, Recall: {recall_lgbm:.4f}\")\n",
    "# print(f\"XGBoost - Precision: {precision_xgb:.4f}, Recall: {recall_xgb:.4f}\")\n",
    "# print(f\"Random Forest - Precision: {precision_rf:.4f}, Recall: {recall_rf:.4f}\")\n",
    "\n",
    "# # 找到一個共同的閾值\n",
    "# common_thresholds = np.arange(0.3, 0.7, 0.01)  # 可以根據需要調整範圍\n",
    "# f1_scores_common = []\n",
    "\n",
    "# for threshold in common_thresholds:\n",
    "#     f1_lgbm = f1_score(y_test.label, (y_probabilities_lgbm >= threshold).astype(int))\n",
    "#     f1_xgb = f1_score(y_test.label, (y_probabilities_xgb >= threshold).astype(int))\n",
    "#     f1_rf = f1_score(y_test.label, (y_probabilities_rf >= threshold).astype(int))\n",
    "#     avg_f1 = (f1_lgbm + f1_xgb + f1_rf) / 3\n",
    "#     f1_scores_common.append(avg_f1)\n",
    "\n",
    "# best_common_threshold = common_thresholds[np.argmax(f1_scores_common)]\n",
    "# print(f\"Best common threshold: {best_common_threshold:.2f}\")\n",
    "\n",
    "# # 計算並打印使用共同閾值的結果\n",
    "# for model_name, y_prob in [('LightGBM', y_probabilities_lgbm), \n",
    "#                            ('XGBoost', y_probabilities_xgb), \n",
    "#                            ('Random Forest', y_probabilities_rf)]:\n",
    "#     y_pred = (y_prob >= best_common_threshold).astype(int)\n",
    "#     precision = precision_score(y_test.label, y_pred)\n",
    "#     recall = recall_score(y_test.label, y_pred)\n",
    "#     f1 = f1_score(y_test.label, y_pred)\n",
    "#     print(f\"{model_name} (Common Threshold) - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(y_true, y_prob, thresholds):\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# 使用更精細的閾值範圍\n",
    "thresholds = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "# 找到每個模型的最佳閾值\n",
    "best_threshold_lgbm, best_f1_lgbm = find_best_threshold(y_test.label, y_probabilities_lgbm, thresholds)\n",
    "best_threshold_rf, best_f1_rf = find_best_threshold(y_test.label, y_probabilities_rf, thresholds)\n",
    "\n",
    "print(f\"LightGBM - Best Threshold: {best_threshold_lgbm:.2f}, Best F1: {best_f1_lgbm:.4f}\")\n",
    "print(f\"Random Forest - Best Threshold: {best_threshold_rf:.2f}, Best F1: {best_f1_rf:.4f}\")\n",
    "\n",
    "# 計算並繪製各個閾值下的F1分數\n",
    "f1_scores_lgbm = [f1_score(y_test.label, (y_probabilities_lgbm >= t).astype(int)) for t in thresholds]\n",
    "f1_scores_rf = [f1_score(y_test.label, (y_probabilities_rf >= t).astype(int)) for t in thresholds]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(thresholds, f1_scores_lgbm, label='LightGBM')\n",
    "plt.plot(thresholds, f1_scores_rf, label='Random Forest')\n",
    "plt.axvline(x=best_threshold_lgbm, color='blue', linestyle='--', label='LightGBM Best')\n",
    "plt.axvline(x=best_threshold_rf, color='green', linestyle='--', label='Random Forest Best')\n",
    "plt.title('F1 Score vs Threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 計算並打印最佳閾值下的精確率和召回率\n",
    "precision_lgbm = precision_score(y_test.label, (y_probabilities_lgbm >= best_threshold_lgbm).astype(int))\n",
    "recall_lgbm = recall_score(y_test.label, (y_probabilities_lgbm >= best_threshold_lgbm).astype(int))\n",
    "\n",
    "precision_rf = precision_score(y_test.label, (y_probabilities_rf >= best_threshold_rf).astype(int))\n",
    "recall_rf = recall_score(y_test.label, (y_probabilities_rf >= best_threshold_rf).astype(int))\n",
    "\n",
    "print(f\"LightGBM - Precision: {precision_lgbm}, Recall: {recall_lgbm}\")\n",
    "print(f\"Random Forest - Precision: {precision_rf}, Recall: {recall_rf}\")\n",
    "\n",
    "# 找到一個共同的閾值\n",
    "common_thresholds = np.arange(0.3, 0.7, 0.01)  # 可以根據需要調整範圍\n",
    "f1_scores_common = []\n",
    "\n",
    "for threshold in common_thresholds:\n",
    "    f1_lgbm = f1_score(y_test.label, (y_probabilities_lgbm >= threshold).astype(int))\n",
    "    f1_rf = f1_score(y_test.label, (y_probabilities_rf >= threshold).astype(int))\n",
    "    avg_f1 = (f1_lgbm + f1_rf) / 2\n",
    "    f1_scores_common.append(avg_f1)\n",
    "\n",
    "best_common_threshold = common_thresholds[np.argmax(f1_scores_common)]\n",
    "print(f\"Best common threshold: {best_common_threshold:.2f}\")\n",
    "\n",
    "# 計算並打印使用共同閾值的結果\n",
    "for model_name, y_prob in [('LightGBM', y_probabilities_lgbm), \n",
    "                           ('Random Forest', y_probabilities_rf)]:\n",
    "    y_pred = (y_prob >= best_common_threshold).astype(int)\n",
    "    precision = precision_score(y_test.label, y_pred)\n",
    "    recall = recall_score(y_test.label, y_pred)\n",
    "    f1 = f1_score(y_test.label, y_pred)\n",
    "    print(f\"{model_name} (Common Threshold) - Precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrated all the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Integrated all the result\n",
    "# y_probabilities_xgb_train = best_xgb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# y_probabilities_lgbm_train = bst.predict(X_test, \n",
    "#                                          num_iteration = bst.best_iteration\n",
    "#                                          )\n",
    "\n",
    "# y_probabilities_rf_train = np.mean([estimator.predict_proba(X_test)[:, 1] for estimator in rf_classifier.estimators_], axis=0)\n",
    "\n",
    "# y_probabilities = (y_probabilities_rf_train + y_probabilities_lgbm_train + y_probabilities_xgb_train) / 3\n",
    "\n",
    "\n",
    "# plt.figure(figsize = (12, 6))\n",
    "# plt.scatter(range(len(y_test)), \n",
    "#             y_probabilities, \n",
    "#             c =  y_test.label, \n",
    "#             cmap = 'viridis', \n",
    "#             alpha = 0.7\n",
    "#             )\n",
    "\n",
    "# plt.colorbar(label = 'True Label')\n",
    "# plt.title('Scatter Plot of Probabilities')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Probability')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_probabilities_combined = (y_probabilities_rf + y_probabilities_lgbm + y_probabilities_xgb) / 3\n",
    "\n",
    "# # 繪製散點圖\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "# models = [('LightGBM', y_probabilities_lgbm), \n",
    "#           ('XGBoost', y_probabilities_xgb), \n",
    "#           ('Random Forest', y_probabilities_rf),\n",
    "#           ('Combined', y_probabilities_combined)]\n",
    "\n",
    "# for i, (model_name, y_prob) in enumerate(models):\n",
    "#     ax = axes[i // 2, i % 2]\n",
    "#     scatter = ax.scatter(range(len(y_test)), y_prob, c=y_test.label, cmap='viridis', alpha=0.7)\n",
    "#     ax.set_title(f'Scatter Plot of Probabilities in {model_name}')\n",
    "#     ax.set_xlabel('Sample Index')\n",
    "#     ax.set_ylabel('Probability')\n",
    "#     fig.colorbar(scatter, ax=ax, label='True Label')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # 計算評估指標的函數\n",
    "# def calculate_metrics(y_true, y_prob, thresholds):\n",
    "#     predictions = [(y_prob >= threshold).astype(int) for threshold in thresholds]\n",
    "#     precision_values = [precision_score(y_true, prediction) for prediction in predictions]\n",
    "#     recall_values = [recall_score(y_true, prediction) for prediction in predictions]\n",
    "#     f1_values = [f1_score(y_true, prediction) for prediction in predictions]\n",
    "#     return precision_values, recall_values, f1_values\n",
    "\n",
    "# # 計算各模型的評估指標\n",
    "# thresholds = np.arange(0.01, 1, 0.01)\n",
    "# metrics = {}\n",
    "# for model_name, y_prob in models:\n",
    "#     metrics[model_name] = calculate_metrics(y_test.label, y_prob, thresholds)\n",
    "\n",
    "# # 繪製 Precision-Recall 曲線\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for model_name, (precision, recall, _) in metrics.items():\n",
    "#     plt.plot(recall, precision, label=model_name)\n",
    "# plt.title('Precision-Recall Curve')\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # 繪製 F1 分數曲線\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for model_name, (_, _, f1) in metrics.items():\n",
    "#     plt.plot(thresholds, f1, label=model_name)\n",
    "# plt.title('F1 Score vs Threshold')\n",
    "# plt.xlabel('Threshold')\n",
    "# plt.ylabel('F1 Score')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # 繪製 ROC 曲線\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for model_name, y_prob in models:\n",
    "#     fpr, tpr, _ = roc_curve(y_test.label, y_prob)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "# plt.plot([0, 1], [0, 1], '--', color='gray', label='Random')\n",
    "# plt.title('ROC Curve')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prediction on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pub = pd.read_csv(\"X_test_pub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probabilities_lgbm = bst.predict(X_test_pub, \n",
    "                                   num_iteration = bst.best_iteration\n",
    "                                   )\n",
    "\n",
    "y_probabilities_rf = np.mean([estimator.predict_proba(X_test_pub)[:, 1] for estimator in rf_classifier.estimators_], axis=0)\n",
    "\n",
    "# y_probabilities_xgb = best_xgb_model.predict_proba(X_test_pub)[:,1]\n",
    "\n",
    "# y_probabilities = (y_probabilities_lgbm + y_probabilities_rf + y_probabilities_xgb)/3\n",
    "# in two model\n",
    "y_probabilities = (y_probabilities_lgbm + y_probabilities_rf) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_test = pd.read_csv(\"X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從原始測試數據中提取 'txkey' 和 'pred' 列\n",
    "df_out = df_raw_test[['txkey', 'label']]\n",
    "\n",
    "# 創建新的數據框，只包含所需的列\n",
    "df_final = pd.DataFrame({\n",
    "    'index': range(len(df_out)),  # 從 0 開始的序列\n",
    "    'label': df_out['label']  # 使用 'pred' 列的數據\n",
    "})\n",
    "\n",
    "# 設置數據框的索引從 1 開始\n",
    "# df_final.index = range(0, len(df_final))\n",
    "\n",
    "# 驗證結果\n",
    "print(df_final.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('./result/RF+LightGBM+XG_test7.csv', \n",
    "              index = False, \n",
    "              encoding = 'utf-8'\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
